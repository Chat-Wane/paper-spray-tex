\newcommand\SCALE{0.49}

% \section{Introduction}

Peer-sampling
protocols~\cite{jelasity2007gossip,tolgyeski2009adaptive,voulgaris2005cyclon}
constitute a fundamental mechanism for a number of large-scale
distributed applications both on the Cloud~\cite{decandia2007dynamo}
and in a peer-to-peer
setting~\cite{Frey09Middleware,voulgaris2005sub,wuhib2009robust}. By
providing each node with a continuously changing partial view of the
network, they make applications resilient to churn~\cite{bertier-d2ht}
and inherently load balancing~\cite{Frey09DSN}. In the context of
video streaming, for example, a peer-sampling protocol makes it
possible to distribute the streaming load over all peers without
requiring the creation and the maintenance of rigid structures like
multiple trees~\cite{Frey09DSN,monod:THESIS}.

The recent introduction of WebRTC~\cite{webrtc} has renewed the
research interest in applications that require peer-sampling protocols
such as content-delivery
networks~\cite{Zhang:2013:MBC:2465351.2465379}, real-time
collaborative editors~\cite{nedelec2016crate}, or video streaming
platforms~\cite{hivejs,smoothcache2}. However, deploying existing
peer-sampling protocols on top of WebRTC raises important technical
challenges.
\begin{inparaenum}[(1)]
\item WebRTC does not manage addressing nor routing; this makes
  connection establishment much more costly than on IP networks and
  more likely to fail. 
\item Browsers run on desktops, laptops and mobile phones. This
  requires protocols that reduce resource consumption as much as
  possible.
\item The ability to launch WebRTC sessions through simple HTTP links
  exposes applications to sudden bursts of popularity.
\end{inparaenum}
Consider the example of a user who is streaming a video directly from
his mobile phone to some of his friends. The user suddenly witnesses
some dramatic event, and his friends spread the news by twitting the
stream's address. Instantly a huge number of users connect and start
watching the stream on their laptops and phones. The streaming
mechanisms and the protocols it relies on must be able to adapt to
this sudden burst of popularity, maintaining their quality of service,
while being able to return to their initial configuration when the
popularity burst subsides. 

Unfortunately, existing peer-sampling protocols lack adaptiveness or
reliability in the context of WebRTC. On the one hand,
\SCAMP~\cite{ganesh2001scamp,ganesh2003peer} provides adaptiveness by
maintaining partial views of size $\ln(n)+k$, $n$ being the number of
nodes and $k$ being a constant. However, \SCAMP is not reliable in the
context of WebRTC, for its connection establishment process is based
on random walks and cannot handle the connection failures that often
occur in WebRTC. On the other hand, the most popular approaches like
\CYCLON~\cite{voulgaris2005cyclon} and the whole RPS protocol
family~\cite{jelasity2007gossip} are reliable in the context of WebRTC
but are not adaptive: developers have to configure fixed-size views at
deployment time. This forces developers to oversize partial views to
handle potential bursts, either wasting resources or not provisioning
for large-enough settings. A simple solution to address this problem
estimates the actual number of network nodes by periodically running
an aggregation protocol~\cite{montresor2004robust}, then resizes the
partial views. However, this aggregation protocol would have to run
quite frequently, resulting in significant network overhead to
anticipate a popularity burst that may never happen. 

We address the challenge of dynamically adaptive peer sampling, by
introducing \SPRAY, a novel random peer-sampling protocol that
provides adaptiveness and reliability by locally self-adjusting the
size of partial views at join, leave, and shuffle times. At a marginal
cost, partial view size converges towards $\ln(n)$. This not only
makes our approach adaptive but also outputs the size of the network
to the application level allowing applications to adapt to sudden
burst in popularity at no additional cost.  For example, some
distributed hash table protocols such as D2HT~\cite{bertier-d2ht}
require both the knowledge of the size of the network to compute the
view of each node, and a random peer-sampling protocol to provide
connectivity in the presence of high churn. \SPRAY provides both at
the same cost.  We demonstrate the impact of our approach on two use
cases that use RPS to broadcast messages. The first one implements a
live video streaming based on three-phase
gossip~\cite{Frey09DSN,FlightPath,monod:THESIS}. In this case,
adaptiveness allows message delivery to remain stable even in presence
of burst in popularity. The second one implements a real-time
collaborative editor. In this case, adaptiveness allows the editors to
adjust the traffic to the size of the network.




Inspired by both \SCAMP~\cite{ganesh2001scamp,ganesh2003peer} and
\CYCLON~\cite{voulgaris2005cyclon}. \SPRAY improves the
state-of-the-art in several ways.

\begin{figure*}
  \begin{center}
    \subfloat[Figure A] [add $1+\ln(n)$ links]
    {\input{input/figcycleA.tex}}
    \hspace{20pt}
    \subfloat[Figure B] [constant number of links]
    {\input{input/figcycleB.tex}}
    \hspace{20pt}
    \subfloat[Figure C] [remove $1+\ln(n)$ links]
    {\input{input/figcycleC.tex}}
    \caption{\label{fig:cycle} Life cycle of a peer.}
  \end{center}
\end{figure*}

\paragraph{Adaptive.}
Peers using \SPRAY see their neighborhood size grow and shrink
automatically according to the global network size using local
knowledge only. In addition, the neighborhood size scales
logarithmically compared to the network size. Figure~\ref{fig:cycle}
shows that \SPRAY achieves this by dividing the life cycle of a peer
in 3 phases:
\begin{enumerate}[(i)]
\item When a peer \emph{joins}, we must add a logarithmic number of
  links to the network. The peer joins using a contact peer already
  inside the network. This contact has a neighborhood whose size is
  the logarithm of the network size. The contact simply asks to its
  neighbors to establish a link with the newcomer to get the proper
  global number of arcs.
\item When a peer stays in the network, it periodically \emph{shuffles} its
  neighborhood with one of its current neighbor. During shuffles, the global
  number of arcs must remain constant. Involved peers give a part of their
  neighborhood. They remove the link to given neighbors and the other involved
  peer must create a link to these. Shuffles may create duplicated links that
  must be temporarily kept.  Over shuffles, the number of duplicates remains
  small compared to the network size and becomes negligible as the network
  grows.
\item When a peer \emph{crashes} or \emph{leaves}, we must remove a
  logarithmic number of links. This number must match the number of
  links added during the joining phase of the newest
  peer. Unfortunately, these departures lead to an overzealous removal
  of links. To fix the number of arcs, all but one of the peers that
  have the departed peer in their neighborhoods should create a
  duplicated link. Since they do not know each other, they cannot
  communicate. They thus duplicate their links according to
  probabilities that depend on their neighborhood sizes.
\end{enumerate}

\noindent Figure~\ref{fig:extended} shows the results of an experiment
where 4 distinct networks have sizes that continuously oscillate from
50k to 100k peers, 5k to 10k peers, 500 to 1k peers, and 50 to 100
peers. We measure the average partial view size of peers. We see that
\begin{inparaenum}[(i)]
\item the measures are not far from the theoretical values (dashed);
\item the partial view sizes vary reflecting the network size;
\item the values are more stable when the network is large.
\end{inparaenum}


%\TODO{formula harmonic number.}


\begin{figure}
  \begin{center}
    \includegraphics[width=\SCALE\textwidth]{./img/extended.eps}
    \caption{\label{fig:extended} Neighborhoods grow and shrink reflecting the
      changes of network size.}
  \end{center}
\end{figure}

%% It dynamically adapts the neighborhood of each peer. Thus, the number of
%% connections scales logarithmically with the network size.

\paragraph{Cautious.}
All along the life cycle of a peer, it uses simple
neighbor-to-neighbor interactions to create links.  Peers rely on a
constant number of other nodes to create links regardless of network
size. The chances to execute backup strategies due to network failures
---message losses or peer crashes---are kept to a minimum.


\begin{figure}
  \begin{center}
    \includegraphics[width=\SCALE\textwidth]{./img/clustering.eps}
    \caption{\label{fig:clustering} Fast convergence to a network with low
      clustering coefficient.}
  \end{center}
\end{figure}

\begin{figure*}
  \begin{center}
    \subfloat[Figure A] [\label{fig:estimator} The quality of the network 
    size estimator based on neighborhood size.]
    {\includegraphics[width=\SCALE\textwidth]{img/estimator.eps}}\\
    \subfloat[Figure B] [\label{fig:hardrate} Full message delivery in
    three-phase broadcast.]
    {\includegraphics[width=\SCALE\textwidth]{img/hardrate.eps}}    
    \subfloat[Figure C] [\label{fig:traffic} Outgoing traffic generated by a
    real-time collaborative editing.]
    {\includegraphics[width=\SCALE\textwidth]{img/traffic.eps}}
    \caption{Example of protocols and applications benefiting from \SPRAY.}
  \end{center}
\end{figure*}






\paragraph{Fast.}
The network quickly converges to a topology with properties similar to
those of random graphs. The clustering coefficient is low. The number
of incoming and outgoing arcs is balanced among peers. There exist no
hubs or weakly connected peers. The network becomes robust to massive
failures. The average shortest path
length grows logarithmically. This allows applications to  quickly disseminate messages.\\
Figure~\ref{fig:clustering} shows the results of an experiment
highlighting the fast convergence of random peer-sampling protocols
such as \SPRAY or \CYCLON. In this experiment, peers continuously join
their respective network. The resulting networks see their oldest
peers highly clustered compared to the newest peers. We can see that
\begin{inparaenum}[(i)]
\item both random peer-sampling protocols behave identically by converging to
  small clustering coefficient values;
\item they converge very quickly to a stable topology even when the network
  comprises a large number of peers.
\end{inparaenum}
This means that an application can bootstrap a network all at once and
expect to reach properties similar to those of random graphs in a short
time.

\ \\ \indent \SPRAY alone provides all desirable properties of random peer-sampling
protocols. It maintains a connected topology even in presence of massive network
failures. In addition, its neighborhood size provides an insight on the network
size. Protocols and applications can benefit from this feature. Firstly, we show
the accuracy of a network size estimator using partial view sizes. Secondly, we
provide 2 examples of broadcast protocols.

\paragraph{Estimator.} Figure~\ref{fig:estimator} shows the results of
measurements concerning the average estimation of network size over the actual
network size. The estimator either uses the local partial view size only or the
local view plus the view size of its neighbors. We see that
\begin{inparaenum}[(i)]
\item the estimation is close to the actual network size and
\item using neighborhood, the estimation can be improved.
\end{inparaenum}
This means that an application can improve its estimation on demand depending on
the available resources.

\paragraph{Three-phase broadcast.}
HiveStreaming\footnote{\url{https://www.hivestreaming.com/}} declared
having a customer network of 400k peers~\cite{smoothcache2}. The
upload bitrate required to serve such a large number of users from a
single server would lead to huge operational costs, which can instead
be saved through direct peer-to-peer exchanges. Gossip appears like a
promising solution, but the redundancy associated with naive gossip
dissemination makes it impractical for applications such as video
streaming.  To solve this issue, existing approaches adopt a
three-phase push-pull approach where nodes push message identifiers
and pull only the messages they need. In this three-phase model, peers
should vary their communication partners as often as possible by
grafting a different dissemination tree for each stream packet in
order to equalize everyone's contribution~\cite{Frey09DSN}. But this
has the side effect that not every node receives all messages if the
dissemination fanout is too small for the size of the network.
Figure~\ref{fig:hardrate} shows the results of measurements concerning
the proportion of messages delivered to the whole network over 1k
messages. The network grows over time. We compare a broadcast that
adjusts its fanout (the number of neighbors it sends/forwards a
message to) using the partial view size (\SPRAY), and one that
configures it in advance (\CYCLON). We see that
\begin{inparaenum}
\item when configuring the fanout in advance, the proportion of fully
  delivered messages quickly drops as the network size increases;
\item in contrast, when adjusting the fanout based on the adaptive
  partial view size, the proportion of fully delivered messages remains
  relatively stable.
\end{inparaenum}
This means that applications that require reliable message delivery
can rely on \SPRAY to maintain reliability whatever the network size.


\paragraph{Reliable broadcast.} \CRATE is a real-time editor that allows authors
to write anytime and anywhere, whatever the number of participants, without any
third party~\cite{nedelec2016crate}. Compared to trending Cloud-based editors
such as Google Docs, it alleviates privacy, scalability, and
single-point-of-failure issues while remaining easy to use.  To provide
availability and responsiveness in documents, collaborative editors consider
multiple authors, each hosting a replica of their shared
document~\cite{saito2005optimistic}.  On updates, the local replica is directly
modified. Then, using broadcast, each update is propagated to all the editing
session where it is integrated.  It does not use three-phase broadcast because
\begin{inparaenum}[(i)]
\item each message conveys an operation that remains small in size and
\item real-time editing requires fast propagation (we cannot wait for additional
  round-trip messages to retrieve the updates).
\end{inparaenum} Instead, the broadcast protocol sends each message to all its
neighbors exactly once. \\
Figure~\ref{fig:traffic} shows the results of measurements concerning the
traffic generated by decentralized collaborative editing. This experiment
involves up to 600 real interconnected Web browsers. They type at a constant
pace over time. Each operation is broadcast to the whole network. We see that
\begin{inparaenum}
\item the generated traffic increases over time because of the replicated data
  structure, i.e., message size increases as new characters are inserted in the
  document;
\item the broadcast protocol automatically adapts to the network size so the
  generated traffic reflects it.
\end{inparaenum}

\ \\

\SPRAY makes building scalable decentralized applications in browsers
easy and accessible.  Developers do not need to foresee the network
size targeted by their applications. As in the case of broadcast, many
topology optimization protocols such as the generic
T-Man~\cite{jelasity2009tman} and
Vicinity~\cite{voulgaris2005epidemic} rely on random peer-sampling
protocols. \SPRAY allows such protocols to benefit from its
self-adjusting partial views. Protocols such as
D2HT~\cite{bertier-d2ht} require both an estimator of the network size
and a random peer-sampling protocol. Since \SPRAY provides both at
same cost, a \SPRAY-based D2HT would be an interesting perspective.

% \begin{inparaenum}[(i)]
% \item Experiments show that \SPRAY provides adaptiveness and reliability at a
%   marginal cost.
% \item Use cases demonstrate how the estimation of the network size positively
%   impacts two RPS-based broadcast protocols either on traffic or message
%   delivery.
% \end{inparaenum}



% The rest of this paper is organized as follows: Section~\ref{sec:relatedwork}
% reviews the related work. Section~\ref{sec:problem} states the scientific
% problem. Section~\ref{sec:proposal} details the \SPRAY
% protocol. Section~\ref{sec:experimentation} presents experimentation results of
% \SPRAY and compares them to state-of-the-art. Section~\ref{sec:usecase} details
% our use-cases. We conclude in Section~\ref{sec:conclusion}.




%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../paper"
%%% End:
